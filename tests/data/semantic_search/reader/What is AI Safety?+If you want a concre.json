{"answer": "first AGIs will be built by humans", "context": "If you want a concrete, evocative analogy: picture a two-year-old playing on top of a tablesaw. That said, people are designing tablesaws which auto-stop when skin contacts the blade. In general, a system\u2019s designers may understand the relevant safety issues better than the operators. Indeed, since the first AGIs will be built by humans, any approach to AI safety ultimately relies on human designers asking the right questions. Point is: we can\u2019t avoid the need for designers to ask (at least some of) the right questions upfront. But needing the designers to ask the right questions once is still a lot better than needing every user to ask the right questions every time they use the system. (This perspective ties in nicely with AI alignment as interface design: if an interface offers an easy-to-overlook way to cut your hand off, and relies on users not doing so, then that\u2019s a design problem.", "end": 338, "id": "004-2NaAhMPGub8F2Pbr7", "score": 0.12975016236305237, "start": 304, "title": "The Fusion Power Generator Scenario\n", "url": "https://www.lesswrong.com/posts/2NaAhMPGub8F2Pbr7/the-fusion-power-generator-scenario#:~:text=first%20AGIs%20will%20be%20built%20by%20humans"}