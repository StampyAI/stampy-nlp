[{"abstract": "Ttraditional safety engineering is coming to a turning point moving from deterministic, non-evolving systems operating in well-defined contexts to increasingly autonomous and learning-enabled AI systems which are acting in largely unpredictable operating contexts. We outline some of underlying challenges of safe AI and suggest a rigorous engineering framework for minimizing uncertainty, thereby increasing confidence, up to tolerable levels, in the safe behavior of AI systems.", "authors": ["Harald Rue\u00df", "Simon Burton"], "id": "2201.10436v2", "score": 0.864051461, "title": "Safe AI -- How is this Possible?", "url": "http://arxiv.org/abs/2201.10436v2"}, {"abstract": "The young field of AI Safety is still in the process of identifying its challenges and limitations. In this paper, we formally describe one such impossibility result, namely Unpredictability of AI. We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system. In conclusion, impact of Unpredictability on AI Safety is discussed.", "authors": ["Roman V. Yampolskiy"], "id": "1905.13053v1", "score": 0.860247314, "title": "Unpredictability of AI", "url": "http://arxiv.org/abs/1905.13053v1"}]