[{"score": 0.10742830485105515, "id": "023-cnC2RMWEGiGpJv8go", "metadata": {"text": "On the other hand, there are some services (such as Facebook or Google) that do have extensive data about individual users across a long period of time. However, this data has another issue: it is incomplete in a very systematic way (since it only tracks online behaviour). For instance, someone might go online most days to read course notes and Wikipedia for a class; this is data that would likely be recorded. However, it is less likely that one would have a record of that person taking the final exam, passing the class and then getting an internship based on their class performance. Of course, some pieces of this sequence would be inferable based on some people\u2019s e-mail records, etc., but it would likely be under-represented in the data relative to the record of Wikipedia usage. In either case, some non-trivial degree of inference would be necessary to make sense of such data. (2) Fragility to mis-specification.", "title": "Model Mis-specification and Inverse Reinforcement Learning\n", "url": "https://www.lesswrong.com/posts/cnC2RMWEGiGpJv8go/model-mis-specification-and-inverse-reinforcement-learning#:~:text=extensive%20data%20about%20individual%20users%20across%20a%20long%20period%20of%20time"}}, {"score": 0.04637671262025833, "id": "140-GEPX7jgLMB8vR2qaK", "metadata": {"text": "Experiments involve several publicly available datasets for high-stakes tasks, including recidivism prediction and weapon possession in stop-and-frisk searches. Across tasks, the data points include 3-7 categorical attributes and up to 28 binary features. The learned rule lists are 4 or 5 rules long, meaning it is very easy to read the entire rule list and see how it will handle every data point. The authors observe that on the recividism data, their approach achieves equal accuracy to a proprietary, blackbox \"prediction tool\" (COMPAS) used for recidivism prediction in some places in the US legal system. Lastly, the authors note that the search algorithm may struggle with very high dimensional data where many possibly relevant features are highly correlated.", "title": "Opinions on Interpretable Machine Learning and 70 Summaries of Recent Papers\n", "url": "https://www.lesswrong.com/posts/GEPX7jgLMB8vR2qaK/opinions-on-interpretable-machine-learning-and-70-summaries#:~:text=publicly%20available%20datasets%20for%20high-stakes%20tasks"}}, {"score": 0.02337259240448475, "id": "000-22gPT6L5XEvHqW7bi", "metadata": {"text": "Contents - 1. Motivation - 2. Query-Based Network Analysis - 2.1 Clarifying the Query - 2.2 Two Approaches to Query Answering - 2.3 A Challenge for the Query-Based Approach - 3. Comprehensive Analysis via Pattern Recognition - 4. Conclusion Disclaimer: this post is a collection of preliminary thoughts around a specific question for MSFP\u203219 blogpost writing day. I do not intend to present novel results or define a research agenda. 1. Motivation The capital of Mozambique is Maputo. This is a fact about the world I learned in school many years ago. Some part of my brain must have changed in order to store this fact and allow me to remember it today. It may be possible, in principle, to recover this fact by simply looking at my brain. In this post, I consider an analogous topic in the context of Artificial Intelligence: is it possible to retrieve the knowledge stored in a neural network? This line of enquiry could be a step towards more transparent AI. 2.", "title": "Thoughts on Retrieving Knowledge from Neural Networks\n", "url": "https://www.lesswrong.com/posts/22gPT6L5XEvHqW7bi/thoughts-on-retrieving-knowledge-from-neural-networks#:~:text=simply%20looking%20at%20my%20brain"}}, {"score": 0.005022065714001656, "id": "011-CWD8FxA3yJPmZE9o3", "metadata": {"text": "For sentence selection and recognizing textual entailment, the datasets above seem to be the major sources of training data. For evidence retrieval, I\u2019ve not looked as closely, but there are some very different approaches. The human-assistance tools seem to rely on taking the top results from Google as a starting point and then filter the documents by a few, mostly hard-coded criteria. The more ambitious pipeline approach of Nie at al instead use a neural document matcher which first narrows down relevant documents by simple keyword matching (I think using Wikipedia as its document pool), and then uses the FEVER dataset to train an LSTM-based ANN to learn whether there is a high relatedness, by using the sentences in FEVER listed as evidence for the claim as the positive cases of relatedness. (I think this is an accurate summary.. I found their methods section rather lacking when it came to how the model was trained.", "title": "Automated Fact Checking: A Look at the Field\n", "url": "https://www.lesswrong.com/posts/CWD8FxA3yJPmZE9o3/automated-fact-checking-a-look-at-the-field#:~:text=their%20methods%20section%20rather%20lacking%20when%20it%20came%20to%20how%20the%20model%20was%20trained."}}, {"score": 0.002252846024930477, "id": "001-4DegbDJJiMX2b3EKm", "metadata": {"text": "The database contains research works motivated by, and substantively informing, the challenge of ensuring the safety of TAI, including both technical and meta topics. This initial version of the database has attempted comprehensive coverage only for traditionally formatted research produced in 2016-2020 by organizations with a significant safety focus (~360 items). The database also has significant but non-comprehensive coverage (~570 items) of earlier years, less traditional formats (e.g., blog posts), and non-safety-focused organizations. Usefully, we also have citation counts for essentially all the items for which that is applicable. The core database takes the form of a Zotero library. Snapshots are also available as Google Sheet, CSV, and Zotero RDF. (Compact version for easier human reading: Google Sheet, CSV.) The rest of this post describes the composition of the database in more detail and presents some high-level quantitative analysis of the contents.", "title": "TAI Safety Bibliographic Database\n", "url": "https://www.lesswrong.com/posts/4DegbDJJiMX2b3EKm/tai-safety-bibliographic-database#:~:text=high-level%20quantitative%20analysis%20of%20the%20contents"}}]